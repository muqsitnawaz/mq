I now have comprehensive information about the langchain-anthropic package. Let me provide you with the answer:

## How to Install and Use the langchain-anthropic Partner Package

### Installation

```bash
pip install langchain-anthropic
```

### Basic Usage

1. **Set your API key** (environment variable):
```bash
export ANTHROPIC_API_KEY="your-api-key"
```

2. **Import and instantiate ChatAnthropic**:
```python
from langchain_anthropic import ChatAnthropic

model = ChatAnthropic(
    model="claude-sonnet-4-5-20250929",
    # temperature=,
    # max_tokens=,
    # timeout=,
    # max_retries=,
    # base_url="...",
)
```

3. **Invoke the model**:
```python
response = model.invoke("Hello, Claude!")
```

### Available Classes

The package exports three main components:
- `ChatAnthropic` - Main chat model class for Claude
- `AnthropicLLM` - Legacy LLM interface
- `convert_to_anthropic_tool` - Utility for converting tools to Anthropic format

### Tool Binding Example

```python
from langchain_anthropic import ChatAnthropic
from pydantic import BaseModel, Field

class GetWeather(BaseModel):
    '''Get the current weather in a given location'''
    location: str = Field(..., description="The city and state, e.g. San Francisco, CA")

model = ChatAnthropic(model="claude-sonnet-4-5-20250929", temperature=0)
model_with_tools = model.bind_tools([GetWeather])
model_with_tools.invoke("What is the weather like in San Francisco")
```

### Structured Output Example

```python
from langchain_anthropic import ChatAnthropic
from pydantic import BaseModel, Field

class Movie(BaseModel):
    title: str = Field(..., description="The title of the movie")
    year: int = Field(..., description="The year the movie was released")

model = ChatAnthropic(model="claude-sonnet-4-5")
model_with_structure = model.with_structured_output(Movie, method="json_schema")
response = model_with_structure.invoke("Provide details about the movie Inception")
```

### Key Configuration Options

- `model` - Model name (e.g., "claude-sonnet-4-5-20250929")
- `temperature` - Randomness in generation (0.0-1.0)
- `max_tokens` - Maximum tokens to generate
- `timeout` - Request timeout
- `max_retries` - Number of retries (default: 2)
- `anthropic_api_key` - API key (or use `ANTHROPIC_API_KEY` env var)
- `thinking` - Enable Claude reasoning (e.g., `{"type": "enabled", "budget_tokens": 10000}`)

### Documentation Links

- API Reference: https://reference.langchain.com/python/integrations/langchain_anthropic/
- LangChain Docs: https://docs.langchain.com/oss/python/integrations/providers/anthropic

```metrics
FILES_READ: [/tmp/langchain-bench/libs/partners/anthropic/README.md, /tmp/langchain-bench/libs/partners/README.md, /tmp/langchain-bench/libs/partners/anthropic/langchain_anthropic/__init__.py, /tmp/langchain-bench/libs/partners/anthropic/langchain_anthropic/chat_models.py]
TOTAL_CHARS: 70727
ANSWER: Install with `pip install langchain-anthropic`, set ANTHROPIC_API_KEY env var, then use `from langchain_anthropic import ChatAnthropic` to create a model instance with `ChatAnthropic(model="claude-sonnet-4-5-20250929")`. The package supports tool binding, structured output, streaming, and extended thinking features.
```
